{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,average_precision_score\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_x = pd.read_csv('creditcard_train.csv')\n",
    "test_x = pd.read_csv('creditcard_test.csv')\n",
    "res = test_x[['Index']]\n",
    "del train_x['Index']\n",
    "del test_x['Index']\n",
    "\n",
    "test_x['Class'] = -1\n",
    "data = pd.concat([train_x,test_x],axis=0,ignore_index=True)\n",
    "train_index = data[data['Class']!=-1].index.tolist()\n",
    "test_index = data[data['Class']==-1].index.tolist()\n",
    "data['Time'] = data['Time'].astype(int)\n",
    "data['Day'] = (data['Time']//(3600*24)).astype(int)\n",
    "data['Hour'] = ((data['Time']-data['Day']*24*3600)//(3600)).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "def get_pywt_1(x):\n",
    "    import pywt\n",
    "    db1 = pywt.Wavelet('db1')\n",
    "    A= pywt.wavedec(x, db1,level=4)\n",
    "    return A[0][0]\n",
    "def get_pywt_2(x):\n",
    "    import pywt\n",
    "    db1 = pywt.Wavelet('db1')\n",
    "    A= pywt.wavedec(x, db1,level=4)\n",
    "    return A[0][1]\n",
    "def get_pywt_3(x):\n",
    "    import pywt\n",
    "    db1 = pywt.Wavelet('db1')\n",
    "    A= pywt.wavedec(x, db1,level=4)\n",
    "    return A[1][0]\n",
    "def get_pywt_4(x):\n",
    "    import pywt\n",
    "    db1 = pywt.Wavelet('db1')\n",
    "    A= pywt.wavedec(x, db1,level=4)\n",
    "    return A[1][1]\n",
    "columns=['V'+str(i) for i in range(1,29)]\n",
    "data['xiao1']=data[columns].apply(get_pywt_1,axis=1)\n",
    "data['xiao2']=data[columns].apply(get_pywt_2,axis=1)\n",
    "data['xiao3']=data[columns].apply(get_pywt_3,axis=1)\n",
    "data['xiao4']=data[columns].apply(get_pywt_4,axis=1)\n",
    "\n",
    "\n",
    "pca_cols = []\n",
    "for i in range(1,29):\n",
    "    pca_cols.append('V'+str(i))\n",
    "def getFeature(x):\n",
    "    return ' '.join(x.astype(str).values.tolist())\n",
    "se  = data[pca_cols].apply(getFeature,axis=1)\n",
    "st = pd.Series(se.drop_duplicates().values)\n",
    "\n",
    "data['Id'] = se.map(pd.Series(st.index,index=st.values))\n",
    "\n",
    "for co in ['Id','Amount']:\n",
    "    data[co+'_ount'] = data[co].map(data[co].value_counts())\n",
    "\n",
    "train_x = data.drop(['Id'],axis=1).loc[train_index].reset_index(drop=True)\n",
    "test_x = data.drop(['Id'],axis=1).loc[test_index].reset_index(drop=True)\n",
    "train_y = train_x.pop('Class')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "del test_x['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256327, 38)\n",
      "(28480, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9557861\tbest: 0.9557861 (0)\ttotal: 182ms\tremaining: 1m 31s\n",
      "50:\ttest: 0.9768442\tbest: 0.9768442 (50)\ttotal: 15.2s\tremaining: 2m 13s\n",
      "100:\ttest: 0.9786028\tbest: 0.9793894 (84)\ttotal: 28.6s\tremaining: 1m 53s\n",
      "150:\ttest: 0.9772216\tbest: 0.9793894 (84)\ttotal: 42.5s\tremaining: 1m 38s\n",
      "200:\ttest: 0.9791262\tbest: 0.9799234 (185)\ttotal: 56.1s\tremaining: 1m 23s\n",
      "250:\ttest: 0.9789227\tbest: 0.9799234 (185)\ttotal: 1m 11s\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9799233899\n",
      "bestIteration = 185\n",
      "\n",
      "Shrink model to first 186 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9264799\tbest: 0.9264799 (0)\ttotal: 276ms\tremaining: 2m 17s\n",
      "50:\ttest: 0.9681660\tbest: 0.9683816 (49)\ttotal: 14s\tremaining: 2m 3s\n",
      "100:\ttest: 0.9808358\tbest: 0.9812901 (96)\ttotal: 26.3s\tremaining: 1m 44s\n",
      "150:\ttest: 0.9838321\tbest: 0.9839219 (149)\ttotal: 39.1s\tremaining: 1m 30s\n",
      "200:\ttest: 0.9840470\tbest: 0.9847364 (180)\ttotal: 53.1s\tremaining: 1m 18s\n",
      "250:\ttest: 0.9820076\tbest: 0.9847364 (180)\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9847363842\n",
      "bestIteration = 180\n",
      "\n",
      "Shrink model to first 181 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9323340\tbest: 0.9323340 (0)\ttotal: 447ms\tremaining: 3m 43s\n",
      "50:\ttest: 0.9843015\tbest: 0.9850813 (35)\ttotal: 14.1s\tremaining: 2m 3s\n",
      "100:\ttest: 0.9818963\tbest: 0.9850813 (35)\ttotal: 26.7s\tremaining: 1m 45s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9850812986\n",
      "bestIteration = 35\n",
      "\n",
      "Shrink model to first 36 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9337383\tbest: 0.9337383 (0)\ttotal: 180ms\tremaining: 1m 29s\n",
      "50:\ttest: 0.9649165\tbest: 0.9653795 (47)\ttotal: 14.3s\tremaining: 2m 5s\n",
      "100:\ttest: 0.9701626\tbest: 0.9704513 (99)\ttotal: 27.3s\tremaining: 1m 47s\n",
      "150:\ttest: 0.9729506\tbest: 0.9743195 (130)\ttotal: 41.7s\tremaining: 1m 36s\n",
      "200:\ttest: 0.9748953\tbest: 0.9758527 (181)\ttotal: 56.3s\tremaining: 1m 23s\n",
      "250:\ttest: 0.9749863\tbest: 0.9758527 (181)\ttotal: 1m 10s\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9758527446\n",
      "bestIteration = 181\n",
      "\n",
      "Shrink model to first 182 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9461038\tbest: 0.9461038 (0)\ttotal: 185ms\tremaining: 1m 32s\n",
      "50:\ttest: 0.9818025\tbest: 0.9818025 (50)\ttotal: 14s\tremaining: 2m 3s\n",
      "100:\ttest: 0.9826217\tbest: 0.9835146 (65)\ttotal: 29.2s\tremaining: 1m 55s\n",
      "150:\ttest: 0.9834255\tbest: 0.9835146 (65)\ttotal: 42.6s\tremaining: 1m 38s\n",
      "200:\ttest: 0.9835954\tbest: 0.9839422 (188)\ttotal: 56.3s\tremaining: 1m 23s\n",
      "250:\ttest: 0.9845990\tbest: 0.9848060 (242)\ttotal: 1m 10s\tremaining: 1m 9s\n",
      "300:\ttest: 0.9853705\tbest: 0.9854200 (297)\ttotal: 1m 23s\tremaining: 55.4s\n",
      "350:\ttest: 0.9859074\tbest: 0.9860637 (327)\ttotal: 1m 37s\tremaining: 41.5s\n",
      "400:\ttest: 0.9859225\tbest: 0.9865471 (390)\ttotal: 1m 51s\tremaining: 27.6s\n",
      "450:\ttest: 0.9860717\tbest: 0.9865471 (390)\ttotal: 2m 5s\tremaining: 13.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9865470942\n",
      "bestIteration = 390\n",
      "\n",
      "Shrink model to first 391 iterations.\n",
      "[0.8982797682150906, 0.8250267642221921, 0.830060000314953, 0.8331338115158007, 0.929535631916322]\n",
      "0.8632071952368717\n"
     ]
    }
   ],
   "source": [
    "params_initial_lgb = {\n",
    "        'num_leaves':31, \n",
    "        'learning_rate':0.01, \n",
    "    'boosting':'gbdt',\n",
    "    'min_child_samples':10,\n",
    "\n",
    "    'bagging_fraction':0.7, \n",
    "    'bagging_freq':1,\n",
    "    'feature_fraction':0.7, \n",
    "\n",
    "    'reg_alpha':0,\n",
    "    'reg_lambda':1, \n",
    "    'metric':'binary_logloss',\n",
    "    'objective':'binary'\n",
    "}\n",
    "NBR = 20000\n",
    "VBE = 100\n",
    "ESR = 200\n",
    "def my_score(preds,data_vali):\n",
    "    labels = data_vali.get_label()\n",
    "    return 'AP',average_precision_score(labels, preds),True\n",
    "def searchBestCut(ytrue,ypre):\n",
    "    lst = []\n",
    "    for i in range(10,81,1):\n",
    "        lst.append(f1_score(ytrue,(pd.Series(ypre)>=i*0.01).astype(int).values))\n",
    "    se = pd.Series(lst,index=range(10,81,1)).sort_values()\n",
    "    return (se.index[-1])*0.01,se.values[-1]\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "prob = pd.DataFrame()\n",
    "cate = pd.DataFrame()\n",
    "num = 0\n",
    "apscore = []\n",
    "fscore = []\n",
    "\n",
    "X = np.array(train_x)\n",
    "Y = np.array(train_y)\n",
    "X_test = np.array(test_x)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,random_state=2020,shuffle=True)\n",
    "for train_part_index,evals_index in skf.split(train_x,train_y):\n",
    "    EVAL_RESULT = {}\n",
    "    X_train, X_val, y_train, y_val = X[train_part_index], X[evals_index], Y[train_part_index], Y[evals_index]\n",
    "\n",
    "    model = cb.CatBoostClassifier( iterations=500,\n",
    "                                   depth = 8,\n",
    "                                   learning_rate = 0.1,\n",
    "                                   custom_loss='AUC',\n",
    "                                   eval_metric='AUC',\n",
    "                                   bagging_temperature=0.83,\n",
    "                                   od_type='Iter',\n",
    "                                   rsm = 0.8,\n",
    "                                   od_wait= 100,\n",
    "                                   metric_period = 50,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   thread_count = 50,\n",
    "                                   random_seed = 2018\n",
    "\n",
    "                              )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val),use_best_model=True)\n",
    "\n",
    "    \n",
    "    xx_pred = model.predict_proba(X_val)[:,1].reshape((X_val.shape[0],1))\n",
    "    \n",
    "\n",
    "    num+=1\n",
    "\n",
    "    apscore.append(average_precision_score(y_val,xx_pred,average='weighted'))\n",
    "    test_ypre = model.predict_proba(X_test)[:,1].reshape((X_test.shape[0],1))\n",
    "    \n",
    "    if num == 1:\n",
    "        cv_pred = np.array(test_ypre).reshape(-1, 1)\n",
    "    else:\n",
    "        cv_pred = np.hstack((cv_pred, test_ypre.reshape(-1, 1)))\n",
    "    \n",
    "#     prob['prob_'+str(num)]=np.array(test_ypre)\n",
    "#     evals_ypre = bst.predict(train_x.loc[evals_index],num_iteration = best_iter)\n",
    "#     cut,best_score = searchBestCut(train_y.loc[evals_index],evals_ypre)\n",
    "#     fscore.append(best_score)\n",
    "#     cate['cate_'+str(num)] = (pd.Series(test_ypre)>=cut).astype(int)\n",
    "#     print(pd.Series(bst.feature_importance(),index=train_x.columns).sort_values(ascending=False).head(10))\n",
    "#     print('\\n')\n",
    "print(apscore)\n",
    "print(sum(apscore)/5)\n",
    "# print(fscore)\n",
    "# print(sum(fscore)/5)\n",
    "# res['Pred'] = prob.mean(1)\n",
    "# res['Class'] = (cate.mean(1)>=0.6).astype(int)\n",
    "# res.to_csv('result/Test_Pred_Class2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45593717e-04],\n",
       "       [4.32358783e-04],\n",
       "       [8.06488765e-05],\n",
       "       ...,\n",
       "       [2.48775402e-05],\n",
       "       [1.45198508e-05],\n",
       "       [2.12646361e-05]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_ypre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28480, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(cv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28450</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28451</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28452</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28453</th>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28454</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28455</th>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28456</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28457</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28458</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28459</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28460</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28461</th>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28462</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28463</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28464</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28465</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28466</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28467</th>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28468</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28469</th>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28470</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28471</th>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28472</th>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28473</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28474</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28475</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28476</th>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28477</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28478</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28479</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28480 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4\n",
       "0      0.000146  0.000160  0.000290  0.000059  0.000109\n",
       "1      0.000432  0.000096  0.000740  0.000328  0.000949\n",
       "2      0.000081  0.000213  0.000596  0.000125  0.000102\n",
       "3      0.000068  0.000051  0.000214  0.000033  0.000027\n",
       "4      0.000083  0.000069  0.000371  0.000123  0.000077\n",
       "5      0.000024  0.000015  0.000177  0.000015  0.000004\n",
       "6      0.000015  0.000016  0.000131  0.000036  0.000012\n",
       "7      0.000021  0.000013  0.000141  0.000035  0.000015\n",
       "8      0.000076  0.000017  0.000166  0.000040  0.000008\n",
       "9      0.001407  0.000348  0.005126  0.001436  0.000820\n",
       "10     0.001374  0.000108  0.000383  0.000132  0.000048\n",
       "11     0.000064  0.000007  0.000236  0.000032  0.000047\n",
       "12     0.000476  0.000125  0.000462  0.001028  0.000842\n",
       "13     0.000074  0.000034  0.000122  0.000086  0.000111\n",
       "14     0.000074  0.000034  0.000122  0.000086  0.000111\n",
       "15     0.000015  0.000026  0.000141  0.000040  0.000007\n",
       "16     0.000065  0.000254  0.000238  0.000164  0.000381\n",
       "17     0.000121  0.000037  0.000246  0.000037  0.000066\n",
       "18     0.000024  0.000015  0.000140  0.000037  0.000001\n",
       "19     0.000107  0.000401  0.000734  0.000328  0.000103\n",
       "20     0.000013  0.000017  0.000144  0.000038  0.000013\n",
       "21     0.000244  0.000063  0.000385  0.000600  0.000189\n",
       "22     0.000054  0.000031  0.000187  0.000037  0.000013\n",
       "23     0.000041  0.000020  0.000220  0.000041  0.000011\n",
       "24     0.000014  0.000056  0.000141  0.000085  0.000015\n",
       "25     0.000418  0.000318  0.000808  0.000196  0.000176\n",
       "26     0.000066  0.000027  0.000268  0.000072  0.000051\n",
       "27     0.000037  0.000019  0.000200  0.000117  0.000010\n",
       "28     0.000093  0.000022  0.000645  0.000172  0.000072\n",
       "29     0.000081  0.000042  0.000351  0.000056  0.000046\n",
       "...         ...       ...       ...       ...       ...\n",
       "28450  0.000011  0.000010  0.000164  0.000018  0.000014\n",
       "28451  0.000341  0.000068  0.000577  0.000272  0.000037\n",
       "28452  0.000018  0.000015  0.000132  0.000017  0.000010\n",
       "28453  0.000084  0.000629  0.000778  0.000145  0.000141\n",
       "28454  0.000017  0.000064  0.000132  0.000031  0.000042\n",
       "28455  0.000485  0.000989  0.000978  0.001273  0.000565\n",
       "28456  0.000229  0.001208  0.000332  0.000141  0.002428\n",
       "28457  0.000015  0.000027  0.000105  0.000012  0.000008\n",
       "28458  0.000071  0.000053  0.000198  0.000081  0.000055\n",
       "28459  0.000600  0.000135  0.000828  0.000550  0.000871\n",
       "28460  0.000026  0.000028  0.000156  0.000028  0.000017\n",
       "28461  0.000108  0.000223  0.000165  0.000039  0.000106\n",
       "28462  0.000081  0.000213  0.000324  0.000338  0.000048\n",
       "28463  0.000027  0.000027  0.000143  0.000038  0.000003\n",
       "28464  0.000041  0.000077  0.000221  0.000126  0.000063\n",
       "28465  0.000021  0.000021  0.000106  0.000046  0.000004\n",
       "28466  0.000007  0.000008  0.000096  0.000010  0.000004\n",
       "28467  0.000931  0.000175  0.000245  0.000104  0.000069\n",
       "28468  0.000021  0.000043  0.000196  0.000063  0.000030\n",
       "28469  0.000650  0.000265  0.000231  0.000153  0.000299\n",
       "28470  0.000008  0.000066  0.000178  0.000128  0.000017\n",
       "28471  0.001090  0.000960  0.000336  0.000941  0.000926\n",
       "28472  0.000202  0.000922  0.000464  0.000491  0.000040\n",
       "28473  0.000061  0.000059  0.000146  0.000023  0.000028\n",
       "28474  0.000076  0.000053  0.000285  0.000357  0.000139\n",
       "28475  0.000006  0.000011  0.000106  0.000012  0.000007\n",
       "28476  0.000295  0.000215  0.000360  0.000803  0.000189\n",
       "28477  0.000025  0.000025  0.000168  0.000101  0.000036\n",
       "28478  0.000015  0.000029  0.000182  0.000035  0.000010\n",
       "28479  0.000021  0.000015  0.000091  0.000011  0.000006\n",
       "\n",
       "[28480 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv('Test_Pred_Class2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
